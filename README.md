# Python 數據工程師評測

本專案的目標是將技術與財務指標的 JSON 檔，整理成格式乾淨、欄位統一、可供後續機器學習使用的 `.csv` 格式。資料中包含不同類型的時間欄位（每日與季度），因此特別設計了季度轉日期範圍的處理邏輯，並整併所有資料成一筆一行的結構，方便模型訓練與分析。

| 檔案 | 說明 |
|---|---|
| `input_data_technical.txt` | 原始 JSON 檔案 |
| `process_financial_data.py` | 清洗與格式轉換的主程式 |
| `processed_data.csv` | 執行程式後產生的乾淨資料集 |
| `README.md` | 專案說明文件 |

---

## 模型訓練及選用問題

### 1. 如果要達成「能夠預測指定的symbol在90天後，是否有成長10%」的目標，會選用的模型及訓練方式，文字提供選用的模型及原因。

這其實是個經典的「二元分類問題」，目標是預測是否達標。因此：

- 我會從 **XGBoost** 或 **LightGBM** 開始當 baseline  
  - 處理 tabular 資料速度快，效果穩定  
  - 可以很快做特徵重要性排序與交叉驗證

- 特徵設計

| 類型       | 特徵範例 |
|------------|----------|
| 連續型特徵 | 收盤價、成交量、vwap、變動率 |
| 滯後特徵   | 近 5 / 10 / 20 日移動平均、報酬率 |
| 時間特徵   | 當日為第幾季、月、週、是否假日 |
| 技術指標   | RSI、MACD、布林通道上下緣、Volatility |
| 類別型特徵 | symbol（可用 one-hot 或 embedding） |

訓練方式與流程：

- 使用 **時間序列切分**（`TimeSeriesSplit`）以避免資料洩漏
- 分為 **訓練集 / 驗證集 / 測試集**，依時間先後順序排列
- 對連續特徵進行標準化，對類別特徵進行編碼處理
- 評估指標包含：
  - AUC-ROC
  - Precision / Recall
  - PR Curve

> 總結來說，會先從 XGBoost 快速建出 baseline，讓模型能運作、能評估，再逐步導入時間序列建模架構來提升效果。

---

### 2. 在訓練中如何從現有的資料集提取出關鍵影響欄位。

我會結合以下幾種方法：

- **模型內建的重要性分析**（例如 XGBoost 的 feature importance）
- **統計特徵觀察**（例如和標籤的 correlation、自相關分析）
- **滯後特徵**：例如近 7 天、30 天的平均值、最大值、報酬率等
- **財務指標**：若有營收、毛利、資本結構等指標，可設計財務比率

> 訓練初期不求完美，只要能看出訊號，就能逐步迭代優化。

---

### 3. 如何利用目前已有的資料集欄位，推論出更有效的新資料欄位。

直接從現有欄位（像是收盤價、交易量、變動率）出發，可以設計：

- **動能類**：報酬率（30、60、90 天）、RSI、MACD
- **趨勢類**：均線差（MA5 vs MA20）、布林通道位置、斜率
- **風險類**：rolling 標準差（波動率）、最大回檔比
- **量能類**：量增幅、量均比、近期爆量訊號

因為任務是「90 天後是否上漲 ≥10%」，也可以反向構建：

- `future_return_90d`：未來報酬率作為標籤
- `excess_return`: 相對大盤/產業的超額報酬

> 這類資訊會讓模型更能分辨「是整體大盤景氣好」還是「個股本身真的有好的表現」。

---

## 總結與討論

這次專案處理的資料本質是結構化 + 時序性數據，清理工作重點在欄位標準化與時間一致性。若要發展成模型訓練系統，我會建議這樣分層：

1. 清洗與標準化
2. EDA + 更多延伸的特徵工程
3. 二元分類模型（XGBoost）建立 baseline
4. 時間序列進階模型（如 LSTM/TFT）
5. 逐步加入 fundamental 資料與情境測試

